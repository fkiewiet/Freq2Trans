{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72342f17",
   "metadata": {},
   "source": [
    "# Dataset E — Single-source Helmholtz pairs (outer-collar PML)\n",
    "\n",
    "This notebook generates a small supervised dataset of Helmholtz solutions:\n",
    "\n",
    "- **Splits:** train/val/test = **50 / 5 / 5**\n",
    "- **RHS:** **one point source** per sample (random location + random amplitude in **[1, 2]**, random phase)\n",
    "- **Solve:** **direct sparse solve** on an **extended grid** with **outer-collar PML**, then **crop** back to the physical domain\n",
    "- **Frequencies:** sampled from `OMEGA_LIST`.  \n",
    "  We enforce the **“≥ 10 wavelengths across the domain”** requirement **only for ω ≥ 64** (as requested).\n",
    "\n",
    "We save **physical-domain arrays only** (`f_real, f_imag, u_real, u_imag`) plus `meta_json`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94b85e63",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'PMLProfiles' from 'operators.pml' (C:\\Users\\31624\\Documents\\MIT\\Programming\\Freq2Transfer\\src\\operators\\pml.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmedium\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_medium\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mresolution\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m grid_from_ppw_with_pml_extension\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m assemble_helmholtz_matrix\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_pml_profiles\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Imports OK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\Documents\\MIT\\Programming\\Freq2Transfer\\src\\operators\\__init__.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msolve\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m solve_linear_system, compute_residual\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# PML (safe to import here as long as pml.py does NOT import assemble.py)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpml\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     18\u001b[0m     PMLProfiles,                 \u001b[38;5;66;03m# if you added it; otherwise remove\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     choose_pml_params,\n\u001b[0;32m     20\u001b[0m     pml_n_waves,\n\u001b[0;32m     21\u001b[0m     sigma_max_nominal,\n\u001b[0;32m     22\u001b[0m     sigma_max_from_reflection,\n\u001b[0;32m     23\u001b[0m     eta_from_reflection,\n\u001b[0;32m     24\u001b[0m     pml_sigma_1d,\n\u001b[0;32m     25\u001b[0m     stretch_factors_from_sigma,\n\u001b[0;32m     26\u001b[0m     build_pml_profiles,\n\u001b[0;32m     27\u001b[0m     build_stretch_factors,\n\u001b[0;32m     28\u001b[0m     build_pml_profiles_from_grid,  \u001b[38;5;66;03m# if you added this notebook-friendly API\u001b[39;00m\n\u001b[0;32m     29\u001b[0m )\n\u001b[0;32m     31\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;66;03m# Assembly\u001b[39;00m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massemble_helmholtz_matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuild_pml_profiles_from_grid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     52\u001b[0m ]\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'PMLProfiles' from 'operators.pml' (C:\\Users\\31624\\Documents\\MIT\\Programming\\Freq2Transfer\\src\\operators\\pml.py)"
     ]
    }
   ],
   "source": [
    "# ============================\n",
    "# 0) Imports\n",
    "# ============================\n",
    "from __future__ import annotations\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse.linalg as spla\n",
    "\n",
    "# Optional progress bar\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except Exception:\n",
    "    tqdm = lambda x, **kw: x  # fallback\n",
    "\n",
    "# --- project imports ---\n",
    "from core.config import HelmholtzConfig, PMLConfig\n",
    "from core.cases import make_default_cases\n",
    "from core.medium import build_medium\n",
    "from core.resolution import grid_from_ppw_with_pml_extension\n",
    "\n",
    "from operators.assemble import assemble_helmholtz_matrix\n",
    "from operators.pml import build_pml_profiles\n",
    "\n",
    "print(\"✅ Imports OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d8250f",
   "metadata": {},
   "source": [
    "## 1) Experiment configuration\n",
    "\n",
    "A few conventions we use:\n",
    "\n",
    "- The **physical domain** is `[X_MIN, X_MIN+LX] × [Y_MIN, Y_MIN+LY]`.\n",
    "- We build a **physical grid** targeting at least `PPW` points-per-wavelength (via `grid_from_ppw_with_pml_extension`).\n",
    "- We then extend with a **PML collar** of thickness `NPML` grid points on each side.\n",
    "- PML “strength” is stored as `eta = σ_max / |ω|` (dimensionless), consistent with your sweeps.\n",
    "\n",
    "> **10 wavelengths condition (only for ω ≥ 64):**  \n",
    "> Using conservative speed `C_MIN`, the number of wavelengths across `L` is  \n",
    "> `waves = L / (2π C_MIN / ω) = ω L / (2π C_MIN)`.  \n",
    "> We enforce `waves ≥ 10` for ω ≥ 64.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09020c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 1) Settings\n",
    "# ============================\n",
    "\n",
    "# Dataset sizes\n",
    "N_TRAIN = 50\n",
    "N_VAL   = 5\n",
    "N_TEST  = 5\n",
    "\n",
    "# Domain (edit if needed)\n",
    "LX, LY = 1.0, 1.0\n",
    "X_MIN, Y_MIN = 0.0, 0.0\n",
    "\n",
    "# Medium / wavespeed (conservative)\n",
    "C_MIN = 1.0\n",
    "\n",
    "# Resolution target\n",
    "PPW = 10.0\n",
    "\n",
    "# Frequencies to sample from\n",
    "OMEGA_LIST = [32.0, 64.0, 128.0]   # adjust if you want\n",
    "\n",
    "# Enforce ≥10 wavelengths for omega >= this threshold\n",
    "OMEGA_WAVES_ENFORCE_MIN = 64.0\n",
    "N_WAVES_MIN = 10.0\n",
    "\n",
    "# PML policy (baseline from your sweeps)\n",
    "NPML = 40\n",
    "ETA  = 6.0\n",
    "PML_POWER = 2.0   # polynomial order\n",
    "\n",
    "# Source sampling\n",
    "AMP_MIN, AMP_MAX = 1.0, 2.0\n",
    "SOURCE_MARGIN = 0.10  # fraction of domain size (keep away from boundaries)\n",
    "\n",
    "# Output path\n",
    "DATASET_TAG = \"E_outercollar_1src_50_5_5\"\n",
    "OUT_ROOT = Path(f\"data/{DATASET_TAG}\")\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "print(\"Writing dataset to:\", OUT_ROOT.resolve())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee6176a",
   "metadata": {},
   "source": [
    "## 2) Small helpers (wavelength feasibility + grid utilities)\n",
    "\n",
    "The **10 wavelengths** requirement is a *physics/domain* requirement, not a grid requirement:\n",
    "\n",
    "- Wavelength: `λ = 2π C_MIN / ω`\n",
    "- Number of wavelengths across `L`: `L/λ = ω L / (2π C_MIN)`\n",
    "\n",
    "So for ω ≥ 64 we explicitly check that `min(LX, LY)` contains at least 10 wavelengths.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b023383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def waves_across_domain(*, omega: float, lx: float, ly: float, c_min: float) -> tuple[float, float]:\n",
    "    \"\"\"Return (waves_x, waves_y) for conservative c_min.\"\"\"\n",
    "    lam = 2.0 * np.pi * float(c_min) / abs(float(omega))\n",
    "    return float(lx / lam), float(ly / lam)\n",
    "\n",
    "\n",
    "def assert_min_waves_if_needed(*, omega: float, lx: float, ly: float, c_min: float,\n",
    "                               omega_enforce_min: float, n_waves_min: float) -> None:\n",
    "    \"\"\"Enforce ≥ n_waves_min across both directions for omega >= omega_enforce_min.\"\"\"\n",
    "    omega = float(omega)\n",
    "    if omega < float(omega_enforce_min):\n",
    "        return\n",
    "    wx, wy = waves_across_domain(omega=omega, lx=lx, ly=ly, c_min=c_min)\n",
    "    if wx < n_waves_min or wy < n_waves_min:\n",
    "        raise ValueError(\n",
    "            f\"Wavelength constraint failed for omega={omega}: waves_x={wx:.2f}, waves_y={wy:.2f} < {n_waves_min}. \"\n",
    "            f\"Increase omega, increase domain, or lower the waves requirement.\"\n",
    "        )\n",
    "\n",
    "\n",
    "def mesh_ij(grid):\n",
    "    \"\"\"Return X,Y arrays with ij indexing consistent with (nx,ny) fields.\"\"\"\n",
    "    x = np.linspace(float(grid.x_min), float(grid.x_min) + float(grid.lx), int(grid.nx))\n",
    "    y = np.linspace(float(grid.y_min), float(grid.y_min) + float(grid.ly), int(grid.ny))\n",
    "    X, Y = np.meshgrid(x, y, indexing=\"ij\")\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8779d74f",
   "metadata": {},
   "source": [
    "## 3) RHS: one point source (random location + amplitude)\n",
    "\n",
    "We generate a **single** point source per sample:\n",
    "\n",
    "- location sampled uniformly in the interior, keeping a margin away from boundaries\n",
    "- amplitude uniform in `[1, 2]`\n",
    "- phase uniform in `[0, 2π]`\n",
    "\n",
    "RHS is injected on the **nearest grid node**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967d3467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_single_source(*, lx: float, ly: float, x_min: float, y_min: float,\n",
    "                         margin_frac: float, amp_min: float, amp_max: float,\n",
    "                         rng: np.random.Generator) -> dict:\n",
    "    mx = margin_frac * lx\n",
    "    my = margin_frac * ly\n",
    "    x = rng.uniform(x_min + mx, x_min + lx - mx)\n",
    "    y = rng.uniform(y_min + my, y_min + ly - my)\n",
    "    amp = rng.uniform(amp_min, amp_max)\n",
    "    phase = rng.uniform(0.0, 2.0*np.pi)\n",
    "    return {\"x\": float(x), \"y\": float(y), \"amp\": float(amp), \"phase\": float(phase)}\n",
    "\n",
    "\n",
    "def build_rhs_from_source(grid_phys, source: dict) -> np.ndarray:\n",
    "    \"\"\"Nearest-node injection on the physical grid. Returns f_phys (nx,ny) complex.\"\"\"\n",
    "    x = np.linspace(float(grid_phys.x_min), float(grid_phys.x_min) + float(grid_phys.lx), int(grid_phys.nx))\n",
    "    y = np.linspace(float(grid_phys.y_min), float(grid_phys.y_min) + float(grid_phys.ly), int(grid_phys.ny))\n",
    "\n",
    "    ix = int(np.argmin(np.abs(x - source[\"x\"])))\n",
    "    iy = int(np.argmin(np.abs(y - source[\"y\"])))\n",
    "\n",
    "    f = np.zeros((int(grid_phys.nx), int(grid_phys.ny)), dtype=np.complex128)\n",
    "    f[ix, iy] += source[\"amp\"] * np.exp(1j * source[\"phase\"])\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4907685",
   "metadata": {},
   "source": [
    "## 4) One forward solve (direct)\n",
    "\n",
    "For each sample we:\n",
    "\n",
    "1. Enforce the “≥10 wavelengths” rule for ω ≥ 64\n",
    "2. Build a **physical** grid satisfying `PPW`\n",
    "3. Extend with an **outer-collar PML** of thickness `NPML`\n",
    "4. Build `HelmholtzConfig(omega, grid_ext, PMLConfig(thickness, eta, power))`\n",
    "5. Assemble and solve on the **extended** grid\n",
    "6. Crop the solution back to the **physical** grid\n",
    "7. Save physical-domain arrays + metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befd11f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_one_sample(*, omega: float, ppw: float, case_name: str) -> tuple[np.ndarray, np.ndarray, dict]:\n",
    "    # 1) enforce wavelength condition (only for omega >= threshold)\n",
    "    assert_min_waves_if_needed(\n",
    "        omega=omega, lx=LX, ly=LY, c_min=C_MIN,\n",
    "        omega_enforce_min=OMEGA_WAVES_ENFORCE_MIN,\n",
    "        n_waves_min=N_WAVES_MIN,\n",
    "    )\n",
    "\n",
    "    # 2) build grids (physical + extended collar)\n",
    "    ext = grid_from_ppw_with_pml_extension(\n",
    "        omega=float(omega),\n",
    "        ppw=float(ppw),\n",
    "        lx=float(LX),\n",
    "        ly=float(LY),\n",
    "        npml=int(NPML),\n",
    "        c_min=float(C_MIN),\n",
    "        n_min_phys=201,         # keep consistent with your earlier datasets\n",
    "        make_odd_phys=True,\n",
    "        x_min_phys=float(X_MIN),\n",
    "        y_min_phys=float(Y_MIN),\n",
    "    )\n",
    "    gphys = ext.grid_phys\n",
    "    gext  = ext.grid_ext\n",
    "    si, sj = ext.core_slices  # slices in (i,j) indexing for arrays shaped (nx,ny)\n",
    "\n",
    "    # 3) configs (frozen dataclasses)\n",
    "    pml_cfg = PMLConfig(thickness=int(NPML), strength=float(ETA), power=float(PML_POWER))\n",
    "    cfg = HelmholtzConfig(omega=float(omega), grid=gext, pml=pml_cfg, ppw_target=float(ppw))\n",
    "\n",
    "    # 4) medium on extended grid\n",
    "    cases = make_default_cases()\n",
    "    if case_name not in cases:\n",
    "        raise KeyError(f\"Unknown case '{case_name}'. Available: {list(cases.keys())}\")\n",
    "    case = cases[case_name]\n",
    "\n",
    "    X, Y = mesh_ij(gext)\n",
    "    c = build_medium(cfg=cfg, case=case, X=X, Y=Y)  # (nx,ny)\n",
    "\n",
    "    # 5) assemble + pml profiles\n",
    "    # assemble_helmholtz_matrix calls build_pml_profiles internally in your codebase,\n",
    "    # but we also compute it here to include in diagnostics if you want.\n",
    "    A = assemble_helmholtz_matrix(cfg, c)\n",
    "\n",
    "    # 6) RHS: single source on physical grid, embed into extended\n",
    "    src = sample_single_source(\n",
    "        lx=LX, ly=LY, x_min=X_MIN, y_min=Y_MIN,\n",
    "        margin_frac=SOURCE_MARGIN, amp_min=AMP_MIN, amp_max=AMP_MAX, rng=rng\n",
    "    )\n",
    "    f_phys = build_rhs_from_source(gphys, src)  # (nxp,nyp)\n",
    "\n",
    "    f_ext = np.zeros((int(gext.nx), int(gext.ny)), dtype=np.complex128)\n",
    "    f_ext[si, sj] = f_phys\n",
    "\n",
    "    b = f_ext.reshape(-1)\n",
    "\n",
    "    # 7) solve (direct)\n",
    "    t0 = time.perf_counter()\n",
    "    u_vec = spla.spsolve(A, b)\n",
    "    solve_time = time.perf_counter() - t0\n",
    "\n",
    "    u_ext = u_vec.reshape(int(gext.nx), int(gext.ny))\n",
    "    u_phys = u_ext[si, sj].copy()\n",
    "\n",
    "    # residual\n",
    "    r = A @ u_vec - b\n",
    "    res_rel = float(np.linalg.norm(r) / (np.linalg.norm(b) + 1e-30))\n",
    "\n",
    "    wx, wy = waves_across_domain(omega=omega, lx=LX, ly=LY, c_min=C_MIN)\n",
    "\n",
    "    meta = {\n",
    "        \"omega\": float(omega),\n",
    "        \"ppw\": float(ppw),\n",
    "        \"case\": case_name,\n",
    "        \"pml\": {\"npml\": int(NPML), \"eta\": float(ETA), \"power\": float(PML_POWER)},\n",
    "        \"waves\": {\"waves_x\": float(wx), \"waves_y\": float(wy), \"min_required_for_omega>=64\": float(N_WAVES_MIN)},\n",
    "        \"grid_phys\": {\"nx\": int(gphys.nx), \"ny\": int(gphys.ny), \"hx\": float(gphys.hx), \"hy\": float(gphys.hy),\n",
    "                        \"x_min\": float(gphys.x_min), \"y_min\": float(gphys.y_min), \"lx\": float(gphys.lx), \"ly\": float(gphys.ly)},\n",
    "        \"grid_ext\": {\"nx\": int(gext.nx), \"ny\": int(gext.ny), \"hx\": float(gext.hx), \"hy\": float(gext.hy),\n",
    "                       \"x_min\": float(gext.x_min), \"y_min\": float(gext.y_min), \"lx\": float(gext.lx), \"ly\": float(gext.ly)},\n",
    "        \"source\": src,\n",
    "        \"solve_time_sec\": float(solve_time),\n",
    "        \"res_rel\": float(res_rel),\n",
    "    }\n",
    "\n",
    "    return f_phys, u_phys, meta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017d85fd",
   "metadata": {},
   "source": [
    "## 5) Saving samples + manifest\n",
    "\n",
    "We store each sample as a compressed `.npz` containing:\n",
    "\n",
    "- `f_real, f_imag` (float32)\n",
    "- `u_real, u_imag` (float32)\n",
    "- `meta_json` (JSON string)\n",
    "\n",
    "A JSONL manifest is written per split (`manifest_train.jsonl`, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2337b143",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_npz(path: Path, **arrays) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    np.savez_compressed(path, **arrays)\n",
    "\n",
    "\n",
    "def save_sample_npz(out_path: Path, f_phys: np.ndarray, u_phys: np.ndarray, meta: dict) -> None:\n",
    "    save_npz(\n",
    "        out_path,\n",
    "        f_real=np.real(f_phys).astype(np.float32),\n",
    "        f_imag=np.imag(f_phys).astype(np.float32),\n",
    "        u_real=np.real(u_phys).astype(np.float32),\n",
    "        u_imag=np.imag(u_phys).astype(np.float32),\n",
    "        meta_json=np.array([json.dumps(meta)], dtype=object),\n",
    "    )\n",
    "\n",
    "\n",
    "def append_jsonl(path: Path, row: dict) -> None:\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(row) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5918451",
   "metadata": {},
   "source": [
    "## 6) Generate a split\n",
    "\n",
    "We generate `n_samples` items by sampling `omega` uniformly from `OMEGA_LIST`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39085356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split(*, out_root: Path, split: str, n_samples: int, start_id: int, case_name: str) -> list[dict]:\n",
    "    split_dir = out_root / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "    manifest_path = out_root / f\"manifest_{split}.jsonl\"\n",
    "\n",
    "    rows = []\n",
    "    sid = int(start_id)\n",
    "\n",
    "    t_start = time.perf_counter()\n",
    "    solve_times = []\n",
    "\n",
    "    for k in tqdm(range(int(n_samples)), desc=f\"Generating {split}\"):\n",
    "        omega = float(rng.choice(OMEGA_LIST))\n",
    "\n",
    "        f_phys, u_phys, meta = solve_one_sample(omega=omega, ppw=PPW, case_name=case_name)\n",
    "\n",
    "        # filename encodes key parameters\n",
    "        fname = (\n",
    "            f\"{case_name}_sid{sid:06d}_\"\n",
    "            f\"w{int(meta['omega'])}_ppw{PPW:g}_npml{meta['pml']['npml']}_eta{meta['pml']['eta']:g}_ns1.npz\"\n",
    "        )\n",
    "        out_path = split_dir / fname\n",
    "        save_sample_npz(out_path, f_phys, u_phys, meta)\n",
    "\n",
    "        # log\n",
    "        row = {\n",
    "            \"split\": split,\n",
    "            \"file\": str(out_path.as_posix()),\n",
    "            \"case\": case_name,\n",
    "            \"sample_id\": sid,\n",
    "            \"omega\": meta[\"omega\"],\n",
    "            \"ppw\": meta[\"ppw\"],\n",
    "            \"nx\": meta[\"grid_phys\"][\"nx\"],\n",
    "            \"ny\": meta[\"grid_phys\"][\"ny\"],\n",
    "            \"solve_time_sec\": meta[\"solve_time_sec\"],\n",
    "            \"res_rel\": meta[\"res_rel\"],\n",
    "        }\n",
    "        append_jsonl(manifest_path, row)\n",
    "        rows.append(row)\n",
    "\n",
    "        solve_times.append(meta[\"solve_time_sec\"])\n",
    "        sid += 1\n",
    "\n",
    "        # lightweight progress info\n",
    "        if (k + 1) % 10 == 0:\n",
    "            avg = float(np.mean(solve_times[-10:]))\n",
    "            total = time.perf_counter() - t_start\n",
    "            print(f\"  [{split}] {k+1:4d}/{n_samples} | avg solve(last10) {avg:.3f}s | total {total:.1f}s\")\n",
    "\n",
    "    total = time.perf_counter() - t_start\n",
    "    print(f\"✅ Done {split}: {n_samples} samples in {total:.1f}s (avg solve {np.mean(solve_times):.3f}s)\")\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea95d28",
   "metadata": {},
   "source": [
    "## 7) Run generation (50/5/5)\n",
    "\n",
    "This will write files to:\n",
    "\n",
    "- `data/<DATASET_TAG>/train/*.npz`\n",
    "- `data/<DATASET_TAG>/val/*.npz`\n",
    "- `data/<DATASET_TAG>/test/*.npz`\n",
    "\n",
    "and manifests:\n",
    "\n",
    "- `data/<DATASET_TAG>/manifest_train.jsonl`\n",
    "- `data/<DATASET_TAG>/manifest_val.jsonl`\n",
    "- `data/<DATASET_TAG>/manifest_test.jsonl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ceceeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================\n",
    "# 7) Generate dataset\n",
    "# ============================\n",
    "\n",
    "CASE_NAME = \"const\"\n",
    "\n",
    "# optional: clean old data\n",
    "for split in (\"train\", \"val\", \"test\"):\n",
    "    d = OUT_ROOT / split\n",
    "    if d.exists():\n",
    "        for p in d.glob(\"*.npz\"):\n",
    "            p.unlink()\n",
    "    mpath = OUT_ROOT / f\"manifest_{split}.jsonl\"\n",
    "    if mpath.exists():\n",
    "        mpath.unlink()\n",
    "\n",
    "print(\"Generating dataset...\")\n",
    "m_train = generate_split(out_root=OUT_ROOT, split=\"train\", n_samples=N_TRAIN, start_id=0, case_name=CASE_NAME)\n",
    "m_val   = generate_split(out_root=OUT_ROOT, split=\"val\",   n_samples=N_VAL,   start_id=N_TRAIN, case_name=CASE_NAME)\n",
    "m_test  = generate_split(out_root=OUT_ROOT, split=\"test\",  n_samples=N_TEST,  start_id=N_TRAIN + N_VAL, case_name=CASE_NAME)\n",
    "\n",
    "print(\"✅ Dataset complete\")\n",
    "print(\"Manifests:\")\n",
    "print(\" -\", OUT_ROOT / \"manifest_train.jsonl\")\n",
    "print(\" -\", OUT_ROOT / \"manifest_val.jsonl\")\n",
    "print(\" -\", OUT_ROOT / \"manifest_test.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36c30d5",
   "metadata": {},
   "source": [
    "## 8) Quick sanity checks (optional but recommended)\n",
    "\n",
    "We verify:\n",
    "\n",
    "- file counts per split\n",
    "- residual statistics (direct solve should give very small `res_rel`)\n",
    "- show a couple of samples (real/imag parts)\n",
    "\n",
    "If you plan to train CNN/U-Nets later, also check whether shapes vary with ω.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62550ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_manifest(path: Path) -> list[dict]:\n",
    "    rows = []\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            rows.append(json.loads(line))\n",
    "    return rows\n",
    "\n",
    "\n",
    "def stats(xs):\n",
    "    xs = np.asarray(xs, dtype=float)\n",
    "    return {\n",
    "        \"min\": float(xs.min()),\n",
    "        \"p50\": float(np.quantile(xs, 0.50)),\n",
    "        \"p90\": float(np.quantile(xs, 0.90)),\n",
    "        \"max\": float(xs.max()),\n",
    "    }\n",
    "\n",
    "\n",
    "def load_npz(path: Path):\n",
    "    d = np.load(path, allow_pickle=True)\n",
    "    meta = json.loads(str(d[\"meta_json\"][0]))\n",
    "    f = d[\"f_real\"] + 1j*d[\"f_imag\"]\n",
    "    u = d[\"u_real\"] + 1j*d[\"u_imag\"]\n",
    "    return f, u, meta\n",
    "\n",
    "\n",
    "def quick_report(split: str):\n",
    "    man = read_manifest(OUT_ROOT / f\"manifest_{split}.jsonl\")\n",
    "    print(f\"[{split}] N={len(man)}\")\n",
    "    print(\"  solve_time_sec:\", stats([r[\"solve_time_sec\"] for r in man]))\n",
    "    print(\"  res_rel       :\", stats([r[\"res_rel\"] for r in man]))\n",
    "    shapes = set()\n",
    "    for r in man[:10]:\n",
    "        f, u, meta = load_npz(Path(r[\"file\"]))\n",
    "        shapes.add((f.shape, u.shape))\n",
    "    print(\"  shapes (first 10):\", shapes)\n",
    "    return man\n",
    "\n",
    "\n",
    "mtr = quick_report(\"train\")\n",
    "mva = quick_report(\"val\")\n",
    "mte = quick_report(\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c7080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize 2 random training samples: real/imag of u\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for idx in rng.choice(len(mtr), size=min(2, len(mtr)), replace=False):\n",
    "    f, u, meta = load_npz(Path(mtr[idx][\"file\"]))\n",
    "    print(\"Sample:\", Path(mtr[idx][\"file\"]).name, \"| omega:\", meta[\"omega\"], \"| res_rel:\", meta[\"res_rel\"])\n",
    "\n",
    "    plt.figure(figsize=(10,3))\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(np.real(u).T, origin=\"lower\", aspect=\"auto\")\n",
    "    plt.title(\"Re(u)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(np.imag(u).T, origin=\"lower\", aspect=\"auto\")\n",
    "    plt.title(\"Im(u)\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
