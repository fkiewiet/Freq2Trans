{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad13c66b",
   "metadata": {},
   "source": [
    "# Notebook F — Build *iterative-loop* training pairs: (high‑freq residual → high‑freq error)\n",
    "\n",
    "You said you **do not** want an ML model that maps `u_ω′ → u_ω`.  \n",
    "Instead, you want **one ML operator inside the iterative loop**.\n",
    "\n",
    "This notebook generates supervised training pairs for a learned corrector:\n",
    "\n",
    "\\[\n",
    "\\mathcal{C}_\\theta:\\ (r_\\omega^{(k)},\\ c,\\ \\omega) \\mapsto e_\\omega^{(k)}\\approx u_\\omega^* - u_\\omega^{(k)}\n",
    "\\]\n",
    "\n",
    "where:\n",
    "\n",
    "- `u_ω*` is the **direct** high‑frequency solution (ground truth)\n",
    "- `u_ω^{(k)}` is the current iterate (starts from zero)\n",
    "- `r_ω^{(k)} = f - A(ω) u_ω^{(k)}` is the **high‑frequency residual**\n",
    "- `e_ω^{(k)} = u_ω* - u_ω^{(k)}` is the **true high‑frequency error** (training target)\n",
    "\n",
    "## Physics step used to generate iterates (baseline loop)\n",
    "We generate `u_ω^{(k)}` with a *two-frequency* (ω′=ω/2) preconditioned update using **identity transfer**:\n",
    "\n",
    "1. `r = f - A_hi u`\n",
    "2. `e_lo = A_lo^{-1} r`  (solve at ω′)\n",
    "3. `u ← u + e_lo`        (identity up-transfer)\n",
    "\n",
    "This produces a realistic sequence of residual/error pairs without learning any transfer yet.\n",
    "\n",
    "---\n",
    "\n",
    "## What gets saved per training pair\n",
    "For each **sample_id** and **iteration k**, we save an `.npz` containing (physical domain only):\n",
    "\n",
    "- `c` (float32)\n",
    "- `f_re`, `f_im`\n",
    "- `r_re`, `r_im`  (input)\n",
    "- `e_re`, `e_im`  (target = true error)\n",
    "- metadata JSON: omega, omega_low, iter, rhs metadata, norms, etc.\n",
    "\n",
    "We also create an `index.csv` (written with Python `csv`, no pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d1b123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Imports: use functions defined in src/ ----\n",
    "import json\n",
    "import csv\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.config import HelmholtzConfig, PMLConfig\n",
    "from core.cases import make_default_cases\n",
    "from core.medium import build_medium\n",
    "from core.rhs import RHSConfig, assemble_rhs\n",
    "from core.resolution import grid_from_ppw_with_pml_extension\n",
    "from core.grid import embed_in_extended, extract_physical\n",
    "\n",
    "from operators.assemble import assemble_helmholtz_matrix\n",
    "from operators.solve import solve_linear_system, compute_residual, solve_helmholtz\n",
    "\n",
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c99a98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Configuration (edit here)\n",
    "# =========================\n",
    "\n",
    "OUT_ROOT = Path(\"data/iterloop_residual_to_error_dataset\")\n",
    "OUT_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Physical domain size\n",
    "LX, LY = 1.0, 1.0\n",
    "\n",
    "# Frequencies (requested: lowest ω′ = 32, ω = 2 ω′)\n",
    "OMEGA_LOW_LIST = [32, 40, 48, 56, 64]   # ω′ values\n",
    "RATIO = 2.0                              # ω = 2 ω′\n",
    "\n",
    "# Grid rule (physical grid must be >= 501×501)\n",
    "PPW = 10.0\n",
    "N_MIN_PHYS = 501\n",
    "\n",
    "# Tuned PML settings from your sweep\n",
    "NPML = 40\n",
    "ETA = 7.0\n",
    "PML_POWER = 3.0\n",
    "\n",
    "# RHS: random 1–5 delta-like sources (narrow Gaussians)\n",
    "RHS_CFG = RHSConfig(\n",
    "    mode=\"random_gaussians\",\n",
    "    k_min=1,\n",
    "    k_max=5,\n",
    "    amp_dist=\"uniform\",\n",
    "    amp_scale=1.0,\n",
    "    complex_amps=True,\n",
    "    width_min_cells=1.5,\n",
    "    width_max_cells=2.5,\n",
    "    avoid_pml=True,\n",
    "    pml_margin_cells=4,\n",
    "    normalize=\"l2\",\n",
    "    target_norm=1.0,\n",
    "    base_seed=0,\n",
    "    include_omega_in_seed=False,  # same RHS for (ω′, ω)\n",
    "    zero_boundary=True,\n",
    ")\n",
    "\n",
    "# Iterations per sample (how many (r->e) pairs to extract)\n",
    "N_ITER = 3\n",
    "\n",
    "# Dataset sizes (small first; scale later)\n",
    "N_TRAIN = 50\n",
    "N_VAL   = 5\n",
    "N_TEST  = 5\n",
    "\n",
    "# Medium\n",
    "CASES = make_default_cases()\n",
    "CASE_NAME = \"const\"\n",
    "\n",
    "# Reproducibility (omega selection)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86037cf",
   "metadata": {},
   "source": [
    "## Core routine: one sample → multiple (residual, error) pairs\n",
    "\n",
    "We keep new logic minimal and orchestrate existing `src/` functions:\n",
    "\n",
    "- Build **one shared extended grid** using ω (high).\n",
    "- Build medium `c` + RHS `f` on the physical grid.\n",
    "- Embed into extended arrays.\n",
    "- Assemble `A_hi` and `A_lo` (sparse).\n",
    "- Compute **direct ground truth** `u_hi*` via `solve_helmholtz`.\n",
    "- Run `N_ITER` refinement steps starting from `u=0` to get iterates.\n",
    "- At each k, compute:\n",
    "  - `r_k = f - A_hi u_k`  (input)\n",
    "  - `e_k = u_hi* - u_k`   (target)\n",
    "\n",
    "All saved arrays are **physical-domain slices** (easy for ML)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16ab10b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_one_sample_pairs(*, omega_low: float, sample_id: int, case_name: str = CASE_NAME, n_iter: int = N_ITER):\n",
    "    omega_low = float(omega_low)\n",
    "    omega_high = float(RATIO) * omega_low\n",
    "    case = CASES[case_name]\n",
    "\n",
    "    # 1) Shared extended grid built from omega_high\n",
    "    ext = grid_from_ppw_with_pml_extension(\n",
    "        omega=omega_high,\n",
    "        ppw=PPW,\n",
    "        lx=LX, ly=LY,\n",
    "        npml=NPML,\n",
    "        c_min=1.0,\n",
    "        n_min_phys=N_MIN_PHYS,\n",
    "        make_odd_phys=True,\n",
    "        x_min_phys=0.0,\n",
    "        y_min_phys=0.0,\n",
    "    )\n",
    "    gphys, gext = ext.grid_phys, ext.grid_ext\n",
    "    core = ext.core_slices\n",
    "\n",
    "    # 2) Physical medium and RHS\n",
    "    Xp, Yp = gphys.mesh()\n",
    "    cfg_phys = HelmholtzConfig(omega=omega_low, grid=gphys, pml=None)\n",
    "    c_phys = build_medium(cfg_phys, case, Xp, Yp).astype(float)\n",
    "\n",
    "    f_vec, rhs_meta = assemble_rhs(cfg_phys, case, Xp, Yp, rhs_cfg=RHS_CFG, sample_id=int(sample_id), return_meta=True)\n",
    "    f_phys = np.asarray(f_vec, dtype=np.complex128).reshape(gphys.nx, gphys.ny)\n",
    "\n",
    "    # 3) Embed to extended\n",
    "    c_ref = float(np.min(c_phys))\n",
    "    c_ext = embed_in_extended(c_phys, (gext.nx, gext.ny), core, fill_value=c_ref, dtype=float)\n",
    "    f_ext_2d = embed_in_extended(f_phys, (gext.nx, gext.ny), core, fill_value=0.0, dtype=np.complex128)\n",
    "    f_ext = np.asarray(f_ext_2d).reshape(-1)\n",
    "\n",
    "    # 4) Build configs on extended grid\n",
    "    def mk_cfg(omega: float) -> HelmholtzConfig:\n",
    "        return HelmholtzConfig(\n",
    "            omega=float(omega),\n",
    "            grid=gext,\n",
    "            pml=PMLConfig(thickness=int(NPML), strength=float(ETA * omega), power=float(PML_POWER)),\n",
    "        )\n",
    "\n",
    "    cfg_lo = mk_cfg(omega_low)\n",
    "    cfg_hi = mk_cfg(omega_high)\n",
    "\n",
    "    # 5) Assemble operators\n",
    "    A_lo = assemble_helmholtz_matrix(cfg_lo, c_ext)\n",
    "    A_hi = assemble_helmholtz_matrix(cfg_hi, c_ext)\n",
    "\n",
    "    # 6) Ground truth high-frequency solution u_hi*\n",
    "    sol_hi = solve_helmholtz(cfg_hi, c=c_ext, f=f_ext, return_matrix=False, return_residual=True)\n",
    "    u_hi_star_ext = sol_hi[\"u\"]                   # vector on extended\n",
    "    U_hi_star_phys = extract_physical(sol_hi[\"U\"], core)\n",
    "\n",
    "    # 7) Iterative loop starting from u=0 (extended vector)\n",
    "    u = np.zeros_like(f_ext, dtype=np.complex128)\n",
    "\n",
    "    pairs = []\n",
    "    f_norm = float(np.linalg.norm(f_ext) + 1e-30)\n",
    "\n",
    "    for k in range(int(n_iter)):\n",
    "        # residual at high frequency\n",
    "        r_ext = compute_residual(A_hi, u, f_ext)\n",
    "\n",
    "        # true error (target) on extended\n",
    "        e_true_ext = u_hi_star_ext - u\n",
    "\n",
    "        # store physical-domain slices for ML\n",
    "        r_phys = extract_physical(r_ext.reshape(gext.nx, gext.ny), core)\n",
    "        e_phys = extract_physical(e_true_ext.reshape(gext.nx, gext.ny), core)\n",
    "\n",
    "        pairs.append({\n",
    "            \"k\": k,\n",
    "            \"c\": c_phys,\n",
    "            \"f\": f_phys,\n",
    "            \"r\": r_phys,\n",
    "            \"e\": e_phys,\n",
    "            \"omega_low\": omega_low,\n",
    "            \"omega_high\": omega_high,\n",
    "            \"rhs_meta\": rhs_meta,\n",
    "            \"rel_res\": float(np.linalg.norm(r_ext) / f_norm),\n",
    "            \"u_norm\": float(np.linalg.norm(u)),\n",
    "        })\n",
    "\n",
    "        # physics update using low-frequency solve as preconditioner (identity transfer)\n",
    "        e_lo_ext = solve_linear_system(A_lo, r_ext)\n",
    "        u = u + e_lo_ext\n",
    "\n",
    "    meta_common = {\n",
    "        \"case\": case_name,\n",
    "        \"sample_id\": int(sample_id),\n",
    "        \"omega_low\": omega_low,\n",
    "        \"omega_high\": omega_high,\n",
    "        \"grid_phys\": {\"nx\": int(gphys.nx), \"ny\": int(gphys.ny), \"lx\": float(gphys.lx), \"ly\": float(gphys.ly), \"hx\": float(gphys.hx), \"hy\": float(gphys.hy)},\n",
    "        \"grid_ext\": {\"nx\": int(gext.nx), \"ny\": int(gext.ny), \"lx\": float(gext.lx), \"ly\": float(gext.ly), \"hx\": float(gext.hx), \"hy\": float(gext.hy)},\n",
    "        \"pml\": {\"npml\": int(NPML), \"eta\": float(ETA), \"power\": float(PML_POWER)},\n",
    "        \"rhs_meta\": rhs_meta,\n",
    "        \"direct_solve_norms\": sol_hi.get(\"norms\", {}),\n",
    "    }\n",
    "\n",
    "    return pairs, meta_common"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7f14d5",
   "metadata": {},
   "source": [
    "## Visualization helper (intuition)\n",
    "\n",
    "We visualize, per iteration `k`:\n",
    "\n",
    "- `|r_k|` (input the ML model will see)\n",
    "- `|e_k|` (target error the ML model should predict)\n",
    "- (optional) `Re(r_k)` and `Re(e_k)`\n",
    "\n",
    "Also plot a simple convergence trace: `rel_res(k)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722f74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_iter_pairs(pairs, *, show_real=False):\n",
    "    rel_res = [p[\"rel_res\"] for p in pairs]\n",
    "    plt.figure(figsize=(4.5, 3.0))\n",
    "    plt.plot(range(len(rel_res)), rel_res, marker=\"o\")\n",
    "    plt.yscale(\"log\")\n",
    "    plt.title(\"High-frequency relative residual per iter\")\n",
    "    plt.xlabel(\"k\")\n",
    "    plt.ylabel(\"||r_k||2 / ||f||2\")\n",
    "    plt.grid(True, which=\"both\", ls=\":\")\n",
    "    plt.show()\n",
    "\n",
    "    for p in pairs:\n",
    "        r = p[\"r\"]\n",
    "        e = p[\"e\"]\n",
    "        k = p[\"k\"]\n",
    "        fig, ax = plt.subplots(1, 2, figsize=(8.5, 3.3))\n",
    "        im0 = ax[0].imshow(np.abs(r), origin=\"lower\"); ax[0].set_title(f\"|r_{k}|\")\n",
    "        im1 = ax[1].imshow(np.abs(e), origin=\"lower\"); ax[1].set_title(f\"|e_{k}| (true error)\")\n",
    "        for a in ax:\n",
    "            a.set_xticks([]); a.set_yticks([])\n",
    "        fig.colorbar(im1, ax=ax, fraction=0.03, pad=0.03)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        if show_real:\n",
    "            fig, ax = plt.subplots(1, 2, figsize=(8.5, 3.3))\n",
    "            im0 = ax[0].imshow(np.real(r), origin=\"lower\"); ax[0].set_title(f\"Re(r_{k})\")\n",
    "            im1 = ax[1].imshow(np.real(e), origin=\"lower\"); ax[1].set_title(f\"Re(e_{k})\")\n",
    "            for a in ax:\n",
    "                a.set_xticks([]); a.set_yticks([])\n",
    "            fig.colorbar(im1, ax=ax, fraction=0.03, pad=0.03)\n",
    "            plt.tight_layout()\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffcbc95d",
   "metadata": {},
   "source": [
    "## Smoke test: build one sample and inspect the pairs\n",
    "\n",
    "This should:\n",
    "- run a direct high-frequency solve\n",
    "- run `N_ITER` refinement steps from `u=0`\n",
    "- plot residuals and true errors per iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e905fd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "omega_low = OMEGA_LOW_LIST[0]\n",
    "pairs, meta = build_one_sample_pairs(omega_low=omega_low, sample_id=0, n_iter=N_ITER)\n",
    "\n",
    "print(\"Meta:\", {k: meta[k] for k in [\"case\",\"sample_id\",\"omega_low\",\"omega_high\",\"pml\"]})\n",
    "print(\"Per-iter rel_res:\", [p[\"rel_res\"] for p in pairs])\n",
    "\n",
    "plot_iter_pairs(pairs, show_real=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b4cb53e",
   "metadata": {},
   "source": [
    "## Saving `.npz` pairs (no pandas)\n",
    "\n",
    "We save one `.npz` per (sample_id, iter k).  \n",
    "This keeps loading trivial and avoids huge monolithic files early on.\n",
    "\n",
    "Filename pattern:\n",
    "`{case}_sid{sample_id:06d}_k{k}_w{omega_low}_w{omega_high}.npz`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47747111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def save_pair_npz(folder: Path, *, sample_id: int, k: int, case: str, omega_low: float, omega_high: float,\n",
    "                  c: np.ndarray, f: np.ndarray, r: np.ndarray, e: np.ndarray, meta_common: dict, meta_iter: dict):\n",
    "    folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    meta = dict(meta_common)\n",
    "    meta.update(meta_iter)\n",
    "    meta[\"created_utc\"] = datetime.datetime.utcnow().isoformat() + \"Z\"\n",
    "\n",
    "    c = c.astype(np.float32)\n",
    "    f = f.astype(np.complex64)\n",
    "    r = r.astype(np.complex64)\n",
    "    e = e.astype(np.complex64)\n",
    "\n",
    "    fname = f\"{case}_sid{sample_id:06d}_k{k}_w{int(omega_low)}_w{int(omega_high)}.npz\"\n",
    "    np.savez_compressed(\n",
    "        folder / fname,\n",
    "        c=c,\n",
    "        f_re=np.real(f).astype(np.float32),\n",
    "        f_im=np.imag(f).astype(np.float32),\n",
    "        r_re=np.real(r).astype(np.float32),\n",
    "        r_im=np.imag(r).astype(np.float32),\n",
    "        e_re=np.real(e).astype(np.float32),\n",
    "        e_im=np.imag(e).astype(np.float32),\n",
    "        meta_json=json.dumps(meta),\n",
    "    )\n",
    "    return fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8968125",
   "metadata": {},
   "source": [
    "## Generate splits\n",
    "\n",
    "For each `sample_id`, we generate `N_ITER` training pairs (k=0..N_ITER-1).  \n",
    "We also write an `index.csv` listing every saved `.npz` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b594737f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: tqdm progress bar (install if missing)\n",
    "try:\n",
    "    from tqdm import tqdm\n",
    "except ModuleNotFoundError:\n",
    "    %pip -q install tqdm\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c54d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_split(split: str, n_samples: int, start_id: int):\n",
    "    split_dir = OUT_ROOT / split\n",
    "    split_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    rows = []\n",
    "    sid = int(start_id)\n",
    "\n",
    "    for _ in tqdm(range(n_samples), desc=f\"Generating {split}\"):\n",
    "        omega_low = float(np.random.choice(OMEGA_LOW_LIST))\n",
    "        pairs, meta_common = build_one_sample_pairs(omega_low=omega_low, sample_id=sid, n_iter=N_ITER)\n",
    "\n",
    "        for p in pairs:\n",
    "            k = int(p[\"k\"])\n",
    "            fname = save_pair_npz(\n",
    "                split_dir,\n",
    "                sample_id=sid,\n",
    "                k=k,\n",
    "                case=meta_common[\"case\"],\n",
    "                omega_low=meta_common[\"omega_low\"],\n",
    "                omega_high=meta_common[\"omega_high\"],\n",
    "                c=p[\"c\"], f=p[\"f\"], r=p[\"r\"], e=p[\"e\"],\n",
    "                meta_common=meta_common,\n",
    "                meta_iter={\"iter\": k, \"rel_res\": p[\"rel_res\"], \"u_norm\": p[\"u_norm\"]},\n",
    "            )\n",
    "            rows.append({\n",
    "                \"split\": split,\n",
    "                \"file\": str((split_dir / fname).as_posix()),\n",
    "                \"case\": meta_common[\"case\"],\n",
    "                \"sample_id\": sid,\n",
    "                \"iter\": k,\n",
    "                \"omega_low\": meta_common[\"omega_low\"],\n",
    "                \"omega_high\": meta_common[\"omega_high\"],\n",
    "                \"nx\": meta_common[\"grid_phys\"][\"nx\"],\n",
    "                \"ny\": meta_common[\"grid_phys\"][\"ny\"],\n",
    "                \"rel_res\": p[\"rel_res\"],\n",
    "            })\n",
    "\n",
    "        sid += 1\n",
    "\n",
    "    return rows, sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a70303",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_rows, next_id = generate_split(\"train\", N_TRAIN, 0)\n",
    "val_rows, next_id   = generate_split(\"val\",   N_VAL,   next_id)\n",
    "test_rows, next_id  = generate_split(\"test\",  N_TEST,  next_id)\n",
    "\n",
    "index_path = OUT_ROOT / \"index.csv\"\n",
    "with open(index_path, \"w\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(\n",
    "        f,\n",
    "        fieldnames=[\"split\",\"file\",\"case\",\"sample_id\",\"iter\",\"omega_low\",\"omega_high\",\"nx\",\"ny\",\"rel_res\"],\n",
    "    )\n",
    "    writer.writeheader()\n",
    "    for row in (train_rows + val_rows + test_rows):\n",
    "        writer.writerow(row)\n",
    "\n",
    "print(\"Wrote index:\", index_path)\n",
    "print(\"Example row:\", (train_rows[0] if train_rows else None))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3d401d",
   "metadata": {},
   "source": [
    "## Quick QC: load a few saved pairs\n",
    "\n",
    "We reload a few `.npz` pairs and plot `|r|` and `|e|` to verify correctness after saving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20911a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def load_pair_npz(path: Path):\n",
    "    d = np.load(path, allow_pickle=True)\n",
    "    meta = json.loads(str(d[\"meta_json\"]))\n",
    "    out = {\n",
    "        \"c\": d[\"c\"],\n",
    "        \"f\": d[\"f_re\"] + 1j*d[\"f_im\"],\n",
    "        \"r\": d[\"r_re\"] + 1j*d[\"r_im\"],\n",
    "        \"e\": d[\"e_re\"] + 1j*d[\"e_im\"],\n",
    "        \"meta\": meta,\n",
    "    }\n",
    "    return out\n",
    "\n",
    "train_files = list((OUT_ROOT / \"train\").glob(\"*.npz\"))\n",
    "for p in random.sample(train_files, k=min(3, len(train_files))):\n",
    "    s = load_pair_npz(p)\n",
    "    print(\"Loaded:\", p.name, \"sid:\", s[\"meta\"][\"sample_id\"], \"k:\", s[\"meta\"][\"iter\"], \"ω:\", s[\"meta\"][\"omega_high\"])\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8.5, 3.3))\n",
    "    im0 = ax[0].imshow(np.abs(s[\"r\"]), origin=\"lower\"); ax[0].set_title(\"|r| (input)\")\n",
    "    im1 = ax[1].imshow(np.abs(s[\"e\"]), origin=\"lower\"); ax[1].set_title(\"|e| (target)\")\n",
    "    for a in ax:\n",
    "        a.set_xticks([]); a.set_yticks([])\n",
    "    fig.colorbar(im1, ax=ax, fraction=0.03, pad=0.03)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
